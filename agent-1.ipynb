{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af3c8849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a140c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "606e367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google API Key Loaded: True\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()  # load environment variables from .env\n",
    "\n",
    "# --- Environment Variable Checks ---\n",
    "google_api_key_loaded = os.getenv(\"GOOGLE_API_KEY\") is not None\n",
    "\n",
    "print(f\"Google API Key Loaded: {google_api_key_loaded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbbd81f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello there! How can I help you today?' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--caa20523-0367-4195-9b09-1a4193976046-0' usage_metadata={'input_tokens': 4, 'output_tokens': 11, 'total_tokens': 15, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "model = init_chat_model(\"gemini-2.0-flash\", \n",
    "                        model_provider=\"google_genai\",\n",
    "                        temperature=0)\n",
    "# model = init_chat_model(\"gemini-1.5-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "response = model.invoke(\"Hello, world!\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e09a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661865dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add memory\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# Structured Output\n",
    "class WeatherResponse(BaseModel):\n",
    "    conditions: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "875626be",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    # model=\"anthropic:claude-3-7-sonnet-latest\",\n",
    "    # model=\"gemini/gemini-pro\",\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    checkpointer=checkpointer,\n",
    "    response_format=WeatherResponse\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a996687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='aab8d83c-7586-41be-b116-b4860b623ae5'), AIMessage(content='Could you please spell out the full city name?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--6116c7cd-8f36-45d7-8366-f683d888791c-0', usage_metadata={'input_tokens': 20, 'output_tokens': 11, 'total_tokens': 31, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='96880ff2-0b18-484a-88a4-9a061c503092'), AIMessage(content='Could you please provide the full city name, including the state or country? For example, \"San Francisco, USA\".', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--a0b9ef5e-3bd5-48c4-96d3-e72fd78d71c8-0', usage_metadata={'input_tokens': 36, 'output_tokens': 25, 'total_tokens': 61, 'input_token_details': {'cache_read': 0}})], 'structured_response': WeatherResponse(conditions='sunny')}\n",
      "****** structure response is ******\n",
      " conditions='sunny'\n"
     ]
    }
   ],
   "source": [
    "# Run the agent\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "sf_response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n",
    "    config  \n",
    ")\n",
    "print(sf_response)\n",
    "print(\"****** structure response is ******\\n\", sf_response[\"structured_response\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62deb707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Please provide the complete city name, including the state and country, so I can retrieve the weather information.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--9f253082-c4fe-43b3-ab1e-65d75ac0c556-0', usage_metadata={'input_tokens': 89, 'output_tokens': 22, 'total_tokens': 111, 'input_token_details': {'cache_read': 0}})]}}\n",
      "{'generate_structured_response': {'structured_response': WeatherResponse(conditions='sunny')}}\n"
     ]
    }
   ],
   "source": [
    "# Run the agent\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n",
    "    config,\n",
    "    stream_mode=\"updates\" \n",
    "):\n",
    "    print(chunk)\n",
    "# print(\"****** structure response is ******\\n\", sf_response[\"structured_response\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49281316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token content='I cannot' additional_kwargs={} response_metadata={'safety_ratings': []} id='run--f873ba32-001b-4716-8815-73b5873ff05a' usage_metadata={'input_tokens': 150, 'output_tokens': 0, 'total_tokens': 150, 'input_token_details': {'cache_read': 0}}\n",
      "Metadata {'thread_id': '1', 'langgraph_step': 17, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:5e230055-7b41-5053-f053-d40f51972f60', 'checkpoint_ns': 'agent:5e230055-7b41-5053-f053-d40f51972f60', 'ls_provider': 'google_genai', 'ls_model_name': 'gemini-2.0-flash', 'ls_model_type': 'chat', 'ls_temperature': 0.0}\n",
      "\n",
      "\n",
      "Token content=\" look up the weather for 'sf' because it is not a complete city name. Please\" additional_kwargs={} response_metadata={'safety_ratings': []} id='run--f873ba32-001b-4716-8815-73b5873ff05a' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
      "Metadata {'thread_id': '1', 'langgraph_step': 17, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:5e230055-7b41-5053-f053-d40f51972f60', 'checkpoint_ns': 'agent:5e230055-7b41-5053-f053-d40f51972f60', 'ls_provider': 'google_genai', 'ls_model_name': 'gemini-2.0-flash', 'ls_model_type': 'chat', 'ls_temperature': 0.0}\n",
      "\n",
      "\n",
      "Token content=' provide the full city name, including the state or country.\\n' additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--f873ba32-001b-4716-8815-73b5873ff05a' usage_metadata={'input_tokens': -34, 'output_tokens': 33, 'total_tokens': -1, 'input_token_details': {'cache_read': 0}}\n",
      "Metadata {'thread_id': '1', 'langgraph_step': 17, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:5e230055-7b41-5053-f053-d40f51972f60', 'checkpoint_ns': 'agent:5e230055-7b41-5053-f053-d40f51972f60', 'ls_provider': 'google_genai', 'ls_model_name': 'gemini-2.0-flash', 'ls_model_type': 'chat', 'ls_temperature': 0.0}\n",
      "\n",
      "\n",
      "Token content='' additional_kwargs={'function_call': {'name': 'WeatherResponse', 'arguments': '{\"conditions\": \"sunny\"}'}} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--9e6acf26-16e5-46f7-afdf-ac1485ef795d' tool_calls=[{'name': 'WeatherResponse', 'args': {'conditions': 'sunny'}, 'id': '747797cd-0148-4ea4-8211-f14aeced42e0', 'type': 'tool_call'}] usage_metadata={'input_tokens': 141, 'output_tokens': 4, 'total_tokens': 145, 'input_token_details': {'cache_read': 0}} tool_call_chunks=[{'name': 'WeatherResponse', 'args': '{\"conditions\": \"sunny\"}', 'id': '747797cd-0148-4ea4-8211-f14aeced42e0', 'index': None, 'type': 'tool_call_chunk'}]\n",
      "Metadata {'thread_id': '1', 'langgraph_step': 18, 'langgraph_node': 'generate_structured_response', 'langgraph_triggers': ('branch:to:generate_structured_response',), 'langgraph_path': ('__pregel_pull', 'generate_structured_response'), 'langgraph_checkpoint_ns': 'generate_structured_response:93e46df2-cef0-b7b2-089e-f8f41f9125a5', 'checkpoint_ns': 'generate_structured_response:93e46df2-cef0-b7b2-089e-f8f41f9125a5', 'ls_provider': 'google_genai', 'ls_model_name': 'gemini-2.0-flash', 'ls_model_type': 'chat', 'ls_temperature': 0.0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the agent\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n",
    "    config,\n",
    "    stream_mode=\"messages\" \n",
    "):\n",
    "    print(\"Token\", token)\n",
    "    print(\"Metadata\", metadata)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# print(\"****** structure response is ******\\n\", sf_response[\"structured_response\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f78de58",
   "metadata": {},
   "source": [
    "### summarize history of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28b22e71",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'typing' has no attribute 'NotRequired'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangmem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshort_term\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SummarizationNode\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m count_tokens_approximately\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprebuilt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_react_agent\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langmem\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangmem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     create_manage_memory_tool,\n\u001b[0;32m      3\u001b[0m     create_memory_manager,\n\u001b[0;32m      4\u001b[0m     create_memory_searcher,\n\u001b[0;32m      5\u001b[0m     create_memory_store_manager,\n\u001b[0;32m      6\u001b[0m     create_search_memory_tool,\n\u001b[0;32m      7\u001b[0m     create_thread_extractor,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangmem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     Prompt,\n\u001b[0;32m     11\u001b[0m     create_multi_prompt_optimizer,\n\u001b[0;32m     12\u001b[0m     create_prompt_optimizer,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangmem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreflection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReflectionExecutor\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langmem\\knowledge\\__init__.py:22\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Knowledge extraction and semantic memory management.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis module provides utilities for extracting and managing semantic knowledge from conversations:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangmem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextraction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     MemoryPhase,\n\u001b[0;32m     24\u001b[0m     create_memory_manager,\n\u001b[0;32m     25\u001b[0m     create_memory_searcher,\n\u001b[0;32m     26\u001b[0m     create_memory_store_manager,\n\u001b[0;32m     27\u001b[0m     create_thread_extractor,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangmem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mknowledge\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_manage_memory_tool, create_search_memory_tool\n\u001b[0;32m     31\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_manage_memory_tool\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_search_memory_tool\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemoryPhase\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     39\u001b[0m ]\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langmem\\knowledge\\extraction.py:58\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMessagesState\u001b[39;00m(TypedDict):\n\u001b[0;32m     55\u001b[0m     messages: \u001b[38;5;28mlist\u001b[39m[AnyMessage]\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMemoryState\u001b[39;00m(MessagesState):\n\u001b[0;32m     59\u001b[0m     existing: typing\u001b[38;5;241m.\u001b[39mNotRequired[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseModel]]]\n\u001b[0;32m     60\u001b[0m     max_steps: \u001b[38;5;28mint\u001b[39m  \u001b[38;5;66;03m# Default of 1\u001b[39;00m\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langmem\\knowledge\\extraction.py:59\u001b[0m, in \u001b[0;36mMemoryState\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMemoryState\u001b[39;00m(MessagesState):\n\u001b[1;32m---> 59\u001b[0m     existing: \u001b[43mtyping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNotRequired\u001b[49m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseModel]]]\n\u001b[0;32m     60\u001b[0m     max_steps: \u001b[38;5;28mint\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'typing' has no attribute 'NotRequired'"
     ]
    }
   ],
   "source": [
    "from langmem.short_term import SummarizationNode\n",
    "from langchain_core.messages.utils import count_tokens_approximately\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing import Any\n",
    "\n",
    "model = init_chat_model(\"gemini-2.0-flash\", \n",
    "                        model_provider=\"google_genai\",\n",
    "                        temperature=0)\n",
    "# model = init_chat_model(\"gemini-1.5-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "summarization_node = SummarizationNode( \n",
    "    token_counter=count_tokens_approximately,\n",
    "    model=model,\n",
    "    max_tokens=384,\n",
    "    max_summary_tokens=128,\n",
    "    output_messages_key=\"llm_input_messages\",\n",
    ")\n",
    "\n",
    "class State(AgentState):\n",
    "    # NOTE: we're adding this key to keep track of previous summary information\n",
    "    # to make sure we're not summarizing on every LLM call\n",
    "    context: dict[str, Any]  \n",
    "\n",
    "\n",
    "checkpointer = InMemorySaver() \n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    pre_model_hook=summarization_node, \n",
    "    state_schema=State, \n",
    "    checkpointer=checkpointer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae894f4",
   "metadata": {},
   "source": [
    "### Multi Agent Support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66bb759",
   "metadata": {},
   "source": [
    "#### Supervisor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b77064",
   "metadata": {},
   "source": [
    "![image](images\\supervisor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "980dd8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': None}\n",
      "\n",
      "\n",
      "{'flight_assistant': {'messages': [AIMessage(content='OK. I am now in flight booking mode.\\n\\nI can book a flight for you from BOS to JFK. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--773df163-9acb-4638-824a-27687f9172f6-0', usage_metadata={'input_tokens': 63, 'output_tokens': 28, 'total_tokens': 91, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '7625b8ae-63f7-4b2d-ba50-be9a39fda915', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', tool_call_id='7625b8ae-63f7-4b2d-ba50-be9a39fda915')]}}\n",
      "\n",
      "\n",
      "{'hotel_assistant': {'messages': [AIMessage(content='OK. I can book a stay at McKittrick Hotel. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='hotel_assistant', id='run--9c7df04e-11f2-4259-b4fb-40f49be895ff-0', usage_metadata={'input_tokens': 56, 'output_tokens': 18, 'total_tokens': 74, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='hotel_assistant', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '07df917e-8909-4c40-a6df-818ff19eda28', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', tool_call_id='07df917e-8909-4c40-a6df-818ff19eda28')]}}\n",
      "\n",
      "\n",
      "{'supervisor': None}\n",
      "\n",
      "\n",
      "{'hotel_assistant': {'messages': [AIMessage(content='OK. I am now in hotel booking mode.\\n\\nI can book a stay at McKittrick Hotel. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='hotel_assistant', id='run--01809967-9351-48ff-8e3f-3ffcf4003eae-0', usage_metadata={'input_tokens': 140, 'output_tokens': 27, 'total_tokens': 167, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='hotel_assistant', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': 'ae24fc86-22fd-486f-b6ae-6559a2908991', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', tool_call_id='ae24fc86-22fd-486f-b6ae-6559a2908991')]}}\n",
      "\n",
      "\n",
      "{'flight_assistant': {'messages': [AIMessage(content='OK. I am now in flight booking mode.\\n\\nI can book a flight for you from BOS to JFK. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--032c104d-6227-45d5-852a-0d79654d0918-0', usage_metadata={'input_tokens': 147, 'output_tokens': 28, 'total_tokens': 175, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '6588ee03-a0c1-4f49-8d32-2880e05844c0', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', tool_call_id='6588ee03-a0c1-4f49-8d32-2880e05844c0')]}}\n",
      "\n",
      "\n",
      "{'supervisor': None}\n",
      "\n",
      "\n",
      "{'flight_assistant': {'messages': [AIMessage(content='OK. I am now in flight booking mode.\\n\\nI can book a flight for you from BOS to JFK. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--53f9487b-2c27-4293-af36-041f98b6b904-0', usage_metadata={'input_tokens': 240, 'output_tokens': 28, 'total_tokens': 268, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '8ba25c4a-3e8a-4080-a751-e74133e48870', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', tool_call_id='8ba25c4a-3e8a-4080-a751-e74133e48870')]}}\n",
      "\n",
      "\n",
      "{'hotel_assistant': {'messages': [AIMessage(content='OK. I am now in hotel booking mode.\\n\\nI can book a stay at McKittrick Hotel. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='hotel_assistant', id='run--e20c23de-c463-470c-9434-25f60c6ce2f0-0', usage_metadata={'input_tokens': 233, 'output_tokens': 27, 'total_tokens': 260, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='hotel_assistant', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '7da595a2-f2bd-4be2-b97e-fa7eefa207ab', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', tool_call_id='7da595a2-f2bd-4be2-b97e-fa7eefa207ab')]}}\n",
      "\n",
      "\n",
      "{'supervisor': {'messages': [HumanMessage(content='book a flight from BOS to JFK and a stay at McKittrick Hotel', additional_kwargs={}, response_metadata={}, id='82352939-0b34-41e4-ad2f-fce83370daeb'), AIMessage(content='OK. I am now in flight booking mode.\\n\\nI can book a flight for you from BOS to JFK. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--773df163-9acb-4638-824a-27687f9172f6-0', usage_metadata={'input_tokens': 63, 'output_tokens': 28, 'total_tokens': 91, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', id='7c031252-3b46-4f0e-9b25-09d30d24f1bb', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '7625b8ae-63f7-4b2d-ba50-be9a39fda915', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='ec3d9cab-91cf-4866-8f71-6bfd22d78ef1', tool_call_id='7625b8ae-63f7-4b2d-ba50-be9a39fda915'), AIMessage(content='OK. I can book a stay at McKittrick Hotel. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='hotel_assistant', id='run--9c7df04e-11f2-4259-b4fb-40f49be895ff-0', usage_metadata={'input_tokens': 56, 'output_tokens': 18, 'total_tokens': 74, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='hotel_assistant', id='f4f80a0b-800b-4958-a8a3-40fcf6fcf4e7', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '07df917e-8909-4c40-a6df-818ff19eda28', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='45fa3fdf-41fc-45e5-b86d-56db1250942a', tool_call_id='07df917e-8909-4c40-a6df-818ff19eda28'), AIMessage(content='OK. I am now in flight booking mode.\\n\\nI can book a flight for you from BOS to JFK. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--032c104d-6227-45d5-852a-0d79654d0918-0', usage_metadata={'input_tokens': 147, 'output_tokens': 28, 'total_tokens': 175, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', id='0fe101d1-a32a-483d-8816-b37cca830a3d', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '6588ee03-a0c1-4f49-8d32-2880e05844c0', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='9c4e3ff4-a2a4-4573-9db1-def8056198a9', tool_call_id='6588ee03-a0c1-4f49-8d32-2880e05844c0'), AIMessage(content='OK. I am now in hotel booking mode.\\n\\nI can book a stay at McKittrick Hotel. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='hotel_assistant', id='run--01809967-9351-48ff-8e3f-3ffcf4003eae-0', usage_metadata={'input_tokens': 140, 'output_tokens': 27, 'total_tokens': 167, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='hotel_assistant', id='99fe1593-0f5f-4f62-8ea5-48d54e9c2ec5', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': 'ae24fc86-22fd-486f-b6ae-6559a2908991', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='67329225-7fe6-4708-8bce-eb03f2b5068a', tool_call_id='ae24fc86-22fd-486f-b6ae-6559a2908991'), AIMessage(content='OK. I am now in flight booking mode.\\n\\nI can book a flight for you from BOS to JFK. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--53f9487b-2c27-4293-af36-041f98b6b904-0', usage_metadata={'input_tokens': 240, 'output_tokens': 28, 'total_tokens': 268, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', id='a968c705-276b-4f35-aee9-47c35cf0c27a', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '8ba25c4a-3e8a-4080-a751-e74133e48870', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='ce90d21b-7af3-4e0f-b2f0-8d1af601466a', tool_call_id='8ba25c4a-3e8a-4080-a751-e74133e48870'), AIMessage(content='OK. I am now in hotel booking mode.\\n\\nI can book a stay at McKittrick Hotel. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='hotel_assistant', id='run--e20c23de-c463-470c-9434-25f60c6ce2f0-0', usage_metadata={'input_tokens': 233, 'output_tokens': 27, 'total_tokens': 260, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='hotel_assistant', id='af59b169-9902-4897-b042-d07017380e01', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '7da595a2-f2bd-4be2-b97e-fa7eefa207ab', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='e44e7304-b8e2-4381-b7b1-9e3be21c91e1', tool_call_id='7da595a2-f2bd-4be2-b97e-fa7eefa207ab'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'transfer_to_flight_assistant', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='supervisor', id='run--94e7cd24-3a47-4a88-9a8d-bdce564027ab-0', tool_calls=[{'name': 'transfer_to_flight_assistant', 'args': {}, 'id': 'ad2c29f8-b168-4678-999a-1266c9914399', 'type': 'tool_call'}], usage_metadata={'input_tokens': 334, 'output_tokens': 7, 'total_tokens': 341, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to flight_assistant', name='transfer_to_flight_assistant', id='373d1ecd-3835-4c4e-9c0e-6eaa6a1743b3', tool_call_id='ad2c29f8-b168-4678-999a-1266c9914399')]}}\n",
      "\n",
      "\n",
      "{'flight_assistant': {'messages': [AIMessage(content='OK. I am now in flight booking mode.\\n\\nI can book a flight for you from BOS to JFK. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--39198194-0e04-416d-a1e6-dec67301af24-0', usage_metadata={'input_tokens': 333, 'output_tokens': 28, 'total_tokens': 361, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', id='11c654d4-a13d-4485-9c74-2e474886d57e', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '3252ca90-e650-4a6f-8064-59be7db24610', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='0f1c66af-6453-4f27-ae72-ac2cdcc2acdc', tool_call_id='3252ca90-e650-4a6f-8064-59be7db24610')]}}\n",
      "\n",
      "\n",
      "{'supervisor': {'messages': [HumanMessage(content='book a flight from BOS to JFK and a stay at McKittrick Hotel', additional_kwargs={}, response_metadata={}, id='82352939-0b34-41e4-ad2f-fce83370daeb'), AIMessage(content='OK. I am now in flight booking mode.\\n\\nI can book a flight for you from BOS to JFK. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--773df163-9acb-4638-824a-27687f9172f6-0', usage_metadata={'input_tokens': 63, 'output_tokens': 28, 'total_tokens': 91, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', id='7c031252-3b46-4f0e-9b25-09d30d24f1bb', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '7625b8ae-63f7-4b2d-ba50-be9a39fda915', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='ec3d9cab-91cf-4866-8f71-6bfd22d78ef1', tool_call_id='7625b8ae-63f7-4b2d-ba50-be9a39fda915'), AIMessage(content='OK. I can book a stay at McKittrick Hotel. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='hotel_assistant', id='run--9c7df04e-11f2-4259-b4fb-40f49be895ff-0', usage_metadata={'input_tokens': 56, 'output_tokens': 18, 'total_tokens': 74, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='hotel_assistant', id='f4f80a0b-800b-4958-a8a3-40fcf6fcf4e7', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '07df917e-8909-4c40-a6df-818ff19eda28', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='45fa3fdf-41fc-45e5-b86d-56db1250942a', tool_call_id='07df917e-8909-4c40-a6df-818ff19eda28'), AIMessage(content='OK. I am now in flight booking mode.\\n\\nI can book a flight for you from BOS to JFK. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--032c104d-6227-45d5-852a-0d79654d0918-0', usage_metadata={'input_tokens': 147, 'output_tokens': 28, 'total_tokens': 175, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', id='0fe101d1-a32a-483d-8816-b37cca830a3d', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '6588ee03-a0c1-4f49-8d32-2880e05844c0', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='9c4e3ff4-a2a4-4573-9db1-def8056198a9', tool_call_id='6588ee03-a0c1-4f49-8d32-2880e05844c0'), AIMessage(content='OK. I am now in hotel booking mode.\\n\\nI can book a stay at McKittrick Hotel. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='hotel_assistant', id='run--01809967-9351-48ff-8e3f-3ffcf4003eae-0', usage_metadata={'input_tokens': 140, 'output_tokens': 27, 'total_tokens': 167, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='hotel_assistant', id='99fe1593-0f5f-4f62-8ea5-48d54e9c2ec5', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': 'ae24fc86-22fd-486f-b6ae-6559a2908991', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='67329225-7fe6-4708-8bce-eb03f2b5068a', tool_call_id='ae24fc86-22fd-486f-b6ae-6559a2908991'), AIMessage(content='OK. I am now in flight booking mode.\\n\\nI can book a flight for you from BOS to JFK. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--53f9487b-2c27-4293-af36-041f98b6b904-0', usage_metadata={'input_tokens': 240, 'output_tokens': 28, 'total_tokens': 268, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', id='a968c705-276b-4f35-aee9-47c35cf0c27a', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '8ba25c4a-3e8a-4080-a751-e74133e48870', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='ce90d21b-7af3-4e0f-b2f0-8d1af601466a', tool_call_id='8ba25c4a-3e8a-4080-a751-e74133e48870'), AIMessage(content='OK. I am now in hotel booking mode.\\n\\nI can book a stay at McKittrick Hotel. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='hotel_assistant', id='run--e20c23de-c463-470c-9434-25f60c6ce2f0-0', usage_metadata={'input_tokens': 233, 'output_tokens': 27, 'total_tokens': 260, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='hotel_assistant', id='af59b169-9902-4897-b042-d07017380e01', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '7da595a2-f2bd-4be2-b97e-fa7eefa207ab', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='e44e7304-b8e2-4381-b7b1-9e3be21c91e1', tool_call_id='7da595a2-f2bd-4be2-b97e-fa7eefa207ab'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'transfer_to_flight_assistant', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='supervisor', id='run--94e7cd24-3a47-4a88-9a8d-bdce564027ab-0', tool_calls=[{'name': 'transfer_to_flight_assistant', 'args': {}, 'id': 'ad2c29f8-b168-4678-999a-1266c9914399', 'type': 'tool_call'}], usage_metadata={'input_tokens': 334, 'output_tokens': 7, 'total_tokens': 341, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to flight_assistant', name='transfer_to_flight_assistant', id='373d1ecd-3835-4c4e-9c0e-6eaa6a1743b3', tool_call_id='ad2c29f8-b168-4678-999a-1266c9914399'), AIMessage(content='OK. I am now in flight booking mode.\\n\\nI can book a flight for you from BOS to JFK. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--39198194-0e04-416d-a1e6-dec67301af24-0', usage_metadata={'input_tokens': 333, 'output_tokens': 28, 'total_tokens': 361, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', id='11c654d4-a13d-4485-9c74-2e474886d57e', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '3252ca90-e650-4a6f-8064-59be7db24610', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='0f1c66af-6453-4f27-ae72-ac2cdcc2acdc', tool_call_id='3252ca90-e650-4a6f-8064-59be7db24610'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'transfer_to_hotel_assistant', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='supervisor', id='run--7dacc89f-c122-4145-8541-0852f038dd7b-0', tool_calls=[{'name': 'transfer_to_hotel_assistant', 'args': {}, 'id': '60cbfddd-c632-4d1e-a0eb-711d6b158d91', 'type': 'tool_call'}], usage_metadata={'input_tokens': 402, 'output_tokens': 7, 'total_tokens': 409, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to hotel_assistant', name='transfer_to_hotel_assistant', id='42a469e1-7583-4aea-9d04-935121ac77cf', tool_call_id='60cbfddd-c632-4d1e-a0eb-711d6b158d91')]}}\n",
      "\n",
      "\n",
      "{'hotel_assistant': {'messages': [AIMessage(content='OK. I am now in hotel booking mode.\\n\\nI can book a stay at McKittrick Hotel. Is that correct?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='hotel_assistant', id='run--bce12159-a7fc-40ca-8164-532b8e731404-0', usage_metadata={'input_tokens': 394, 'output_tokens': 26, 'total_tokens': 420, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='hotel_assistant', id='317c64a3-12ff-4796-ab05-1145f6635395', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '95ef08c8-a343-4c2b-9f1a-44e401c786f4', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', id='c0113684-6313-4e43-bdf9-1adb8a7cecf2', tool_call_id='95ef08c8-a343-4c2b-9f1a-44e401c786f4')]}}\n",
      "\n",
      "\n",
      "{'supervisor': None}\n",
      "\n",
      "\n",
      "{'flight_assistant': {'messages': [AIMessage(content='Do you want to book a flight from BOS to JFK?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--b69273a8-6ccc-4c80-a3c3-746a3853c251-0', usage_metadata={'input_tokens': 468, 'output_tokens': 13, 'total_tokens': 481, 'input_token_details': {'cache_read': 0}}), AIMessage(content='Transferring back to supervisor', additional_kwargs={}, response_metadata={'__is_handoff_back': True}, name='flight_assistant', tool_calls=[{'name': 'transfer_back_to_supervisor', 'args': {}, 'id': '0b1830a2-4b64-47c2-8ea2-b721ff2fab18', 'type': 'tool_call'}]), ToolMessage(content='Successfully transferred back to supervisor', name='transfer_back_to_supervisor', tool_call_id='0b1830a2-4b64-47c2-8ea2-b721ff2fab18')]}}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 50\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 15\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 47\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 47\u001b[0m\n\u001b[0;32m     31\u001b[0m hotel_assistant \u001b[38;5;241m=\u001b[39m create_react_agent(\n\u001b[0;32m     32\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     33\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[book_hotel],\n\u001b[0;32m     34\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a hotel booking assistant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     35\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhotel_assistant\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     38\u001b[0m supervisor \u001b[38;5;241m=\u001b[39m create_supervisor(\n\u001b[0;32m     39\u001b[0m     agents\u001b[38;5;241m=\u001b[39m[flight_assistant, hotel_assistant],\n\u001b[0;32m     40\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     )\n\u001b[0;32m     45\u001b[0m )\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m supervisor\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m     48\u001b[0m     {\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     50\u001b[0m             {\n\u001b[0;32m     51\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     52\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbook a flight from BOS to JFK and a stay at McKittrick Hotel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m             }\n\u001b[0;32m     54\u001b[0m         ]\n\u001b[0;32m     55\u001b[0m     }\n\u001b[0;32m     56\u001b[0m ):\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(chunk)\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langgraph\\pregel\\__init__.py:2461\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2455\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   2456\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   2458\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   2459\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   2460\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 2461\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2462\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   2463\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2464\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   2465\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2466\u001b[0m         ):\n\u001b[0;32m   2467\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2468\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   2469\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langgraph\\pregel\\runner.py:247\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 247\u001b[0m     \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpanic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tb \u001b[38;5;241m:=\u001b[39m exc\u001b[38;5;241m.\u001b[39m__traceback__:\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langgraph\\pregel\\runner.py:499\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(futs, timeout_exc_cls, panic)\u001b[0m\n\u001b[0;32m    497\u001b[0m                 interrupts\u001b[38;5;241m.\u001b[39mappend(exc)\n\u001b[0;32m    498\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    500\u001b[0m \u001b[38;5;66;03m# raise combined interrupts\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interrupts:\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langgraph\\pregel\\executor.py:80\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Remove the task from the tasks dict when it's done.\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GraphBubbleUp:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:438\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py:52\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langgraph\\utils\\runnable.py:370\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 370\u001b[0m         ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    372\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langgraph_supervisor\\supervisor.py:86\u001b[0m, in \u001b[0;36m_make_call_agent.<locals>.call_agent\u001b[1;34m(state, config)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_agent\u001b[39m(state: \u001b[38;5;28mdict\u001b[39m, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m---> 86\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _process_output(output)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langgraph\\pregel\\__init__.py:2823\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2820\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2821\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2823\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   2824\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2825\u001b[0m     config,\n\u001b[0;32m   2826\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   2827\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   2828\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   2829\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   2830\u001b[0m     checkpoint_during\u001b[38;5;241m=\u001b[39mcheckpoint_during,\n\u001b[0;32m   2831\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   2832\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2833\u001b[0m ):\n\u001b[0;32m   2834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2835\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2836\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m   2837\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m (ints \u001b[38;5;241m:=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mget(INTERRUPT)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2838\u001b[0m         ):\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langgraph\\pregel\\__init__.py:2461\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2455\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   2456\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   2458\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   2459\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   2460\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 2461\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2462\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   2463\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2464\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   2465\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2466\u001b[0m         ):\n\u001b[0;32m   2467\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2468\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   2469\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langgraph\\pregel\\runner.py:153\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    151\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langgraph\\utils\\runnable.py:370\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 370\u001b[0m         ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    372\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langgraph\\prebuilt\\chat_agent_executor.py:745\u001b[0m, in \u001b[0;36mcreate_react_agent.<locals>.call_model\u001b[1;34m(state, config)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_model\u001b[39m(state: StateSchema, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StateSchema:\n\u001b[0;32m    744\u001b[0m     state \u001b[38;5;241m=\u001b[39m _get_model_input_state(state)\n\u001b[1;32m--> 745\u001b[0m     response \u001b[38;5;241m=\u001b[39m cast(AIMessage, \u001b[43mmodel_runnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    746\u001b[0m     \u001b[38;5;66;03m# add agent name to the AIMessage\u001b[39;00m\n\u001b[0;32m    747\u001b[0m     response\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langchain_core\\runnables\\base.py:3034\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3032\u001b[0m                 \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3033\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3034\u001b[0m                 \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3035\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langchain_core\\runnables\\base.py:5416\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5409\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5411\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5414\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5415\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5417\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5418\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5419\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5420\u001b[0m     )\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langchain_google_genai\\chat_models.py:1199\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI.invoke\u001b[1;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1195\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1196\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTools are already defined.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_execution tool can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1197\u001b[0m         )\n\u001b[1;32m-> 1199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:370\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    366\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    367\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    369\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 370\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    371\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    372\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    373\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    374\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    375\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    376\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    377\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    378\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    379\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    380\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:947\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    940\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    945\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    946\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:766\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    765\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 766\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    767\u001b[0m                 m,\n\u001b[0;32m    768\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    769\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    770\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    771\u001b[0m             )\n\u001b[0;32m    772\u001b[0m         )\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    774\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1012\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1012\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1013\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1016\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langchain_google_genai\\chat_models.py:1275\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[1;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1251\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1263\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m   1264\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[0;32m   1265\u001b[0m         messages,\n\u001b[0;32m   1266\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1273\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[0;32m   1274\u001b[0m     )\n\u001b[1;32m-> 1275\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m _chat_with_retry(\n\u001b[0;32m   1276\u001b[0m         request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[0;32m   1277\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1278\u001b[0m         generation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mgenerate_content,\n\u001b[0;32m   1279\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata,\n\u001b[0;32m   1280\u001b[0m     )\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langchain_google_genai\\chat_models.py:210\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[1;34m(generation_method, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chat_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\tenacity\\__init__.py:338\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    336\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    337\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\tenacity\\__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\tenacity\\__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\tenacity\\__init__.py:420\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    418\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\tenacity\\__init__.py:187\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:438\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\tenacity\\__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langchain_google_genai\\chat_models.py:208\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    206\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\langchain_google_genai\\chat_models.py:192\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mFailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:868\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    867\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[0;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\POC's\\langgraph-jupyter-code\\venv_agent_1\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 15\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 47\n}\n]"
     ]
    }
   ],
   "source": [
    "# pip install langgraph-supervisor\n",
    "\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "model = init_chat_model(\"gemini-2.0-flash\", \n",
    "                        model_provider=\"google_genai\",\n",
    "                        temperature=0)\n",
    "\n",
    "@tool\n",
    "def book_hotel(hotel_name: str):\n",
    "    \"\"\"Book a hotel\"\"\"\n",
    "    return f\"Successfully booked a stay at {hotel_name}.\"\n",
    "\n",
    "@tool\n",
    "def book_flight(from_airport: str, to_airport: str):\n",
    "    \"\"\"Book a flight\"\"\"\n",
    "    return f\"Successfully booked a flight from {from_airport} to {to_airport}.\"\n",
    "\n",
    "flight_assistant = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[book_flight],\n",
    "    prompt=\"You are a flight booking assistant\",\n",
    "    name=\"flight_assistant\"\n",
    ")\n",
    "\n",
    "hotel_assistant = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[book_hotel],\n",
    "    prompt=\"You are a hotel booking assistant\",\n",
    "    name=\"hotel_assistant\"\n",
    ")\n",
    "\n",
    "supervisor = create_supervisor(\n",
    "    agents=[flight_assistant, hotel_assistant],\n",
    "    model=model,\n",
    "    prompt=(\n",
    "        \"You manage a hotel booking assistant and a\"\n",
    "        \"flight booking assistant. Assign work to them.\"\n",
    "    )\n",
    ").compile()\n",
    "\n",
    "for chunk in supervisor.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"book a flight from BOS to JFK and a stay at McKittrick Hotel\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da523282",
   "metadata": {},
   "source": [
    "#### Swarm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61362a6",
   "metadata": {},
   "source": [
    "![image](images\\swarm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "691f9db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flight_assistant': {'messages': [HumanMessage(content='book a flight from BOS to JFK and a stay at McKittrick Hotel', additional_kwargs={}, response_metadata={}, id='a1b36c13-c65a-4bb4-8d3c-83f5af235d56'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'book_flight', 'arguments': '{\"from_airport\": \"BOS\", \"to_airport\": \"JFK\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--69115562-e77d-4310-a884-c58f3fb4287b-0', tool_calls=[{'name': 'book_flight', 'args': {'from_airport': 'BOS', 'to_airport': 'JFK'}, 'id': '7daa812a-cabb-4ca3-8ae5-43bbd17fc7c8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 11, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully booked a flight from BOS to JFK.', name='book_flight', id='2d95d128-a61b-4ab0-9be7-cec421f49e08', tool_call_id='7daa812a-cabb-4ca3-8ae5-43bbd17fc7c8'), AIMessage(content='OK. I have booked a flight from BOS to JFK. I will transfer you to the hotel booking assistant to book your stay at the McKittrick Hotel.', additional_kwargs={'function_call': {'name': 'transfer_to_hotel_assistant', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--e7edcff6-8304-46e4-9e16-022846ad8c17-0', tool_calls=[{'name': 'transfer_to_hotel_assistant', 'args': {}, 'id': '8ba321f2-0ea9-4106-94cd-e7013617e6d7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 82, 'output_tokens': 40, 'total_tokens': 122, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to hotel_assistant', name='transfer_to_hotel_assistant', id='eb2f78f3-54c3-469d-958c-e2fbc23f35c2', tool_call_id='8ba321f2-0ea9-4106-94cd-e7013617e6d7')], 'active_agent': 'hotel_assistant'}}\n",
      "\n",
      "\n",
      "{'hotel_assistant': {'messages': [HumanMessage(content='book a flight from BOS to JFK and a stay at McKittrick Hotel', additional_kwargs={}, response_metadata={}, id='a1b36c13-c65a-4bb4-8d3c-83f5af235d56'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'book_flight', 'arguments': '{\"from_airport\": \"BOS\", \"to_airport\": \"JFK\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--69115562-e77d-4310-a884-c58f3fb4287b-0', tool_calls=[{'name': 'book_flight', 'args': {'from_airport': 'BOS', 'to_airport': 'JFK'}, 'id': '7daa812a-cabb-4ca3-8ae5-43bbd17fc7c8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 11, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully booked a flight from BOS to JFK.', name='book_flight', id='2d95d128-a61b-4ab0-9be7-cec421f49e08', tool_call_id='7daa812a-cabb-4ca3-8ae5-43bbd17fc7c8'), AIMessage(content='OK. I have booked a flight from BOS to JFK. I will transfer you to the hotel booking assistant to book your stay at the McKittrick Hotel.', additional_kwargs={'function_call': {'name': 'transfer_to_hotel_assistant', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--e7edcff6-8304-46e4-9e16-022846ad8c17-0', tool_calls=[{'name': 'transfer_to_hotel_assistant', 'args': {}, 'id': '8ba321f2-0ea9-4106-94cd-e7013617e6d7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 82, 'output_tokens': 40, 'total_tokens': 122, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to hotel_assistant', name='transfer_to_hotel_assistant', id='eb2f78f3-54c3-469d-958c-e2fbc23f35c2', tool_call_id='8ba321f2-0ea9-4106-94cd-e7013617e6d7'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'book_hotel', 'arguments': '{\"hotel_name\": \"McKittrick Hotel\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='hotel_assistant', id='run--cda98894-0511-4559-bebf-f76c1544101f-0', tool_calls=[{'name': 'book_hotel', 'args': {'hotel_name': 'McKittrick Hotel'}, 'id': 'e901454e-b963-434f-b672-3ac9a8c1c877', 'type': 'tool_call'}], usage_metadata={'input_tokens': 96, 'output_tokens': 10, 'total_tokens': 106, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully booked a stay at McKittrick Hotel.', name='book_hotel', id='7bc3625a-bbb2-4366-99da-0fdec82efa65', tool_call_id='e901454e-b963-434f-b672-3ac9a8c1c877'), AIMessage(content='OK. I have booked a flight from BOS to JFK and a stay at McKittrick Hotel. Anything else?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='hotel_assistant', id='run--0ceab583-bd29-4792-af77-1a58320143eb-0', usage_metadata={'input_tokens': 120, 'output_tokens': 24, 'total_tokens': 144, 'input_token_details': {'cache_read': 0}})]}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph_swarm import create_swarm, create_handoff_tool\n",
    "\n",
    "transfer_to_hotel_assistant = create_handoff_tool(\n",
    "    agent_name=\"hotel_assistant\",\n",
    "    description=\"Transfer user to the hotel-booking assistant.\",\n",
    ")\n",
    "transfer_to_flight_assistant = create_handoff_tool(\n",
    "    agent_name=\"flight_assistant\",\n",
    "    description=\"Transfer user to the flight-booking assistant.\",\n",
    ")\n",
    "\n",
    "flight_assistant = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[book_flight, transfer_to_hotel_assistant],\n",
    "    prompt=\"You are a flight booking assistant\",\n",
    "    name=\"flight_assistant\"\n",
    ")\n",
    "hotel_assistant = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[book_hotel, transfer_to_flight_assistant],\n",
    "    prompt=\"You are a hotel booking assistant\",\n",
    "    name=\"hotel_assistant\"\n",
    ")\n",
    "\n",
    "swarm = create_swarm(\n",
    "    agents=[flight_assistant, hotel_assistant],\n",
    "    default_active_agent=\"flight_assistant\"\n",
    ").compile()\n",
    "\n",
    "for chunk in swarm.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"book a flight from BOS to JFK and a stay at McKittrick Hotel\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c37b2a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flight_assistant': {'messages': [HumanMessage(content='book a flight from BOS to JFK and a stay at McKittrick Hotel', additional_kwargs={}, response_metadata={}, id='e86b6c8f-c401-426d-8927-447d537edf28'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'book_flight', 'arguments': '{\"from_airport\": \"BOS\", \"to_airport\": \"JFK\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--8d7edea4-092e-481c-9baa-f8d0fb4aa56f-0', tool_calls=[{'name': 'book_flight', 'args': {'from_airport': 'BOS', 'to_airport': 'JFK'}, 'id': '19efa4d2-c685-4bcc-a4fa-6deeabab32c4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 11, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully booked a flight from BOS to JFK.', name='book_flight', id='3d5dd5b1-1140-495f-bb28-63c24cc006a7', tool_call_id='19efa4d2-c685-4bcc-a4fa-6deeabab32c4'), AIMessage(content='OK. I have booked a flight from BOS to JFK. I will transfer you to the hotel booking assistant to book your stay at the McKittrick Hotel.', additional_kwargs={'function_call': {'name': 'transfer_to_hotel_assistant', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--d8ab4622-c496-408d-ad15-8abe46fcc9ca-0', tool_calls=[{'name': 'transfer_to_hotel_assistant', 'args': {}, 'id': '02c9d7e0-6473-480e-9b33-145d1eb37828', 'type': 'tool_call'}], usage_metadata={'input_tokens': 82, 'output_tokens': 40, 'total_tokens': 122, 'input_token_details': {'cache_read': 0}}), {'role': 'tool', 'content': 'Successfully transferred to hotel_assistant', 'name': 'transfer_to_hotel_assistant', 'tool_call_id': '02c9d7e0-6473-480e-9b33-145d1eb37828'}]}}\n",
      "\n",
      "\n",
      "{'hotel_assistant': {'messages': [HumanMessage(content='book a flight from BOS to JFK and a stay at McKittrick Hotel', additional_kwargs={}, response_metadata={}, id='e86b6c8f-c401-426d-8927-447d537edf28'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'book_flight', 'arguments': '{\"from_airport\": \"BOS\", \"to_airport\": \"JFK\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--8d7edea4-092e-481c-9baa-f8d0fb4aa56f-0', tool_calls=[{'name': 'book_flight', 'args': {'from_airport': 'BOS', 'to_airport': 'JFK'}, 'id': '19efa4d2-c685-4bcc-a4fa-6deeabab32c4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 11, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully booked a flight from BOS to JFK.', name='book_flight', id='3d5dd5b1-1140-495f-bb28-63c24cc006a7', tool_call_id='19efa4d2-c685-4bcc-a4fa-6deeabab32c4'), AIMessage(content='OK. I have booked a flight from BOS to JFK. I will transfer you to the hotel booking assistant to book your stay at the McKittrick Hotel.', additional_kwargs={'function_call': {'name': 'transfer_to_hotel_assistant', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='flight_assistant', id='run--d8ab4622-c496-408d-ad15-8abe46fcc9ca-0', tool_calls=[{'name': 'transfer_to_hotel_assistant', 'args': {}, 'id': '02c9d7e0-6473-480e-9b33-145d1eb37828', 'type': 'tool_call'}], usage_metadata={'input_tokens': 82, 'output_tokens': 40, 'total_tokens': 122, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully transferred to hotel_assistant', name='transfer_to_hotel_assistant', id='b306cfc8-cd98-48aa-bc24-3a76aeec7a1e', tool_call_id='02c9d7e0-6473-480e-9b33-145d1eb37828'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'book_hotel', 'arguments': '{\"hotel_name\": \"McKittrick Hotel\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='hotel_assistant', id='run--f3626bd1-9e83-4b9a-bcb7-51430aec73e8-0', tool_calls=[{'name': 'book_hotel', 'args': {'hotel_name': 'McKittrick Hotel'}, 'id': 'fe641937-e008-43a7-91e6-6bd75d58ef60', 'type': 'tool_call'}], usage_metadata={'input_tokens': 96, 'output_tokens': 10, 'total_tokens': 106, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='Successfully booked a stay at McKittrick Hotel.', name='book_hotel', id='33a01a4b-dd98-45fd-a9d5-f0cb7838732b', tool_call_id='fe641937-e008-43a7-91e6-6bd75d58ef60'), AIMessage(content='OK. I have booked a flight from BOS to JFK and a stay at McKittrick Hotel. Anything else?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, name='hotel_assistant', id='run--26dd342e-9ba1-4ea1-ae54-668749021380-0', usage_metadata={'input_tokens': 120, 'output_tokens': 24, 'total_tokens': 144, 'input_token_details': {'cache_read': 0}})]}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langgraph.prebuilt import create_react_agent, InjectedState\n",
    "from langgraph.graph import StateGraph, START, MessagesState\n",
    "from langgraph.types import Command\n",
    "\n",
    "def create_handoff_tool(*, agent_name: str, description: str | None = None):\n",
    "    name = f\"transfer_to_{agent_name}\"\n",
    "    description = description or f\"Transfer to {agent_name}\"\n",
    "\n",
    "    @tool(name, description=description)\n",
    "    def handoff_tool(\n",
    "        state: Annotated[MessagesState, InjectedState], \n",
    "        tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    ) -> Command:\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": f\"Successfully transferred to {agent_name}\",\n",
    "            \"name\": name,\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "        }\n",
    "        return Command(  \n",
    "            goto=agent_name,  \n",
    "            update={\"messages\": state[\"messages\"] + [tool_message]},  \n",
    "            graph=Command.PARENT,  \n",
    "        )\n",
    "    return handoff_tool\n",
    "\n",
    "# Handoffs\n",
    "transfer_to_hotel_assistant = create_handoff_tool(\n",
    "    agent_name=\"hotel_assistant\",\n",
    "    description=\"Transfer user to the hotel-booking assistant.\",\n",
    ")\n",
    "transfer_to_flight_assistant = create_handoff_tool(\n",
    "    agent_name=\"flight_assistant\",\n",
    "    description=\"Transfer user to the flight-booking assistant.\",\n",
    ")\n",
    "\n",
    "# Simple agent tools\n",
    "def book_hotel(hotel_name: str):\n",
    "    \"\"\"Book a hotel\"\"\"\n",
    "    return f\"Successfully booked a stay at {hotel_name}.\"\n",
    "\n",
    "def book_flight(from_airport: str, to_airport: str):\n",
    "    \"\"\"Book a flight\"\"\"\n",
    "    return f\"Successfully booked a flight from {from_airport} to {to_airport}.\"\n",
    "\n",
    "# Define agents\n",
    "flight_assistant = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[book_flight, transfer_to_hotel_assistant],\n",
    "    prompt=\"You are a flight booking assistant\",\n",
    "    name=\"flight_assistant\"\n",
    ")\n",
    "hotel_assistant = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[book_hotel, transfer_to_flight_assistant],\n",
    "    prompt=\"You are a hotel booking assistant\",\n",
    "    name=\"hotel_assistant\"\n",
    ")\n",
    "\n",
    "# Define multi-agent graph\n",
    "multi_agent_graph = (\n",
    "    StateGraph(MessagesState)\n",
    "    .add_node(flight_assistant)\n",
    "    .add_node(hotel_assistant)\n",
    "    .add_edge(START, \"flight_assistant\")\n",
    "    .compile()\n",
    ")\n",
    "\n",
    "# Run the multi-agent graph\n",
    "for chunk in multi_agent_graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"book a flight from BOS to JFK and a stay at McKittrick Hotel\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_agent_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
